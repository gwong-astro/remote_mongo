{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: G. Wong (G.Wong@csiro.au)\n",
    "\n",
    "Purpose: Reading a directory, the parset file and import into mongoDB\n",
    "\n",
    "Date: 04.10.19\n",
    "\n",
    "Execution: run via jupyter notebook\n",
    "\n",
    "Note/s:\n",
    "This script is a \"first run\", so this script would be executed shortly after the gridded dumps (exported from the ASKAP pipeline) have been transferred into the storage before being imported into the DINGO pipelines.\n",
    "\n",
    "After the file has been transferred, you can specify the filepath of the new directory.  The script will list out the files and save it as a entry (key) while it will read the parset.last file and save the information into the database.\n",
    "\n",
    "This script assumes that MongoDB is already running (in two terminals you will need to run \"mongod\" and \"mongo\" on osx). MongoDB can also run on cloud systems such as AWS and Azure.\n",
    "\n",
    "Future development:\n",
    "Create a medata file (within ASKAPsoft), read and save into the database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pymongo  # Assumption that you already have mongoDB installed and running\n",
    "import os       # Used for os.walk, extract the filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a filepath as a string, create a dictionary which then can be used for import (as a json file) into mongoDB\n",
    "def dictionary_creation(directory):\n",
    "    dirFiles = os.listdir(directory) # Extract the directory and files at the filepath\n",
    "\n",
    "    # Create dictionary and lower levels\n",
    "    sbid = '1239' # schedule block ID\n",
    "    parameter_dict = {\"_id\":sbid}\n",
    "    parameter_dict['dataset'] = {}\n",
    "\n",
    "    # Create the dumps nest\n",
    "    parameter_dict['dataset']['dumps'] = {}\n",
    "    for i, files in enumerate(dirFiles):\n",
    "        #  For the parset file you want to read that and then save that information   \n",
    "        modified_key = files.replace('.','_')\n",
    "        # if you want to read files and save the information e.g. metadata        \n",
    "        if files == 'parset.in':\n",
    "            parset = open(('%s/%s' % (directory,files)))\n",
    "            parameter_dict['dataset']['parset'] = {}\n",
    "            parameter_dict['dataset']['parset']['filepath'] = f'{directory}/{files}'\n",
    "            for line in parset:\n",
    "                if not line.startswith(\"#\"):\n",
    "                    parts = line.split(\"=\")\n",
    "                    para_key = parts[0].rstrip().replace('.','_')\n",
    "                    clip_value = parts[1].rstrip('\\n')\n",
    "                    parameter_dict['dataset']['parset'][para_key] = clip_value.lstrip(' ')\n",
    "        #  For now you just want to create separate entries for the different dumps (filename)\n",
    "        else:\n",
    "            parameter_dict['dataset']['dumps'][(f'{modified_key}')] = {'filepath': f'{directory}/{files}'}\n",
    "    # return dictionary \n",
    "    return parameter_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB startup and import\n",
    "def database_start_import(import_dict,client=\"mongodb://localhost:27017/\",dbname = \"test2\",collection=\"observations\"):\n",
    "    # The mongoDB backend should be running, if you are stuck\n",
    "    # run the command 'mongo' and 'mongod' in separate terminals\n",
    "    myclient = pymongo.MongoClient(client)\n",
    "    # print(myclient.list_database_names())  # list all of the databases (debug purpose)\n",
    "    dblist = myclient.list_database_names()  # Alternatively, save it as an list and loop through it\n",
    "    if dbname in dblist:                     # dbname is set to test2 by default\n",
    "        print(\"Database exists: %s\" % dbname)\n",
    "    else:\n",
    "        print(\"New database created: %s\" % dbname)\n",
    "\n",
    "    mydb = myclient[dbname]         # In MongoDB, a database is not created until it gets content!\n",
    "    mycol = mydb[collection]        # Collection table entry\n",
    "    mycol.insert_one(import_dict)   # Data entry\n",
    "    print('Data entered')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database exists: test2\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory\n",
    "directory = '/Users/won10d/Documents/DINGO/development/Testing/example_ASKAPSoft_output'\n",
    "import_data = dictionary_creation(directory)   # create the dictionary based on directory\n",
    "database_start_import(import_dict=import_data) # Take the import data and then start database and save data\n",
    "\n",
    "# print(import_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
